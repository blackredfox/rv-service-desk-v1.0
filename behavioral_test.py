#!/usr/bin/env python3
"""
Comprehensive Backend Testing for RV Service Desk Five Behavioral Fixes

This test suite verifies the implementation of five behavioral fixes:
1. Diagnostic Question Registry
2. Diagnostic Pivot Rules  
3. Fact-Locked Final Report
4. Tone Adjustment
5. Labor Confirmation Input Parsing

Tests focus on module-level functionality and API behaviors.
"""

import subprocess
import sys
import json
import os
from datetime import datetime

class RVServiceDeskBehavioralTester:
    def __init__(self):
        self.app_dir = "/app"
        self.tests_run = 0
        self.tests_passed = 0
        self.results = []

    def log(self, message, level="INFO"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] [{level}] {message}")

    def run_specific_test(self, test_name, test_file):
        """Run a specific test file"""
        self.tests_run += 1
        self.log(f"Running: {test_name}")
        
        try:
            os.chdir(self.app_dir)
            result = subprocess.run(
                ["npx", "vitest", "run", test_file, "--reporter=basic"], 
                capture_output=True, text=True, timeout=60
            )
            
            if result.returncode == 0:
                self.tests_passed += 1
                self.results.append({"test": test_name, "status": "PASS", "details": "‚úÖ"})
                self.log(f"‚úÖ PASS - {test_name}")
                
                # Extract passed test count
                output = result.stdout + result.stderr
                if "passed" in output:
                    lines = output.split('\n')
                    for line in lines:
                        if "‚úì" in line or "passed" in line.lower():
                            details = line.strip()
                            if details and len(details) < 100:
                                self.log(f"   {details}")
                            break
                return True
            else:
                self.results.append({"test": test_name, "status": "FAIL", "details": result.stderr[:200]})
                self.log(f"‚ùå FAIL - {test_name}: {result.stderr[:200]}")
                return False
                
        except Exception as e:
            self.results.append({"test": test_name, "status": "ERROR", "details": str(e)})
            self.log(f"‚ùå ERROR - {test_name}: {str(e)}")
            return False

    def test_diagnostic_registry_behavior(self):
        """Test 1: Diagnostic Question Registry behaviors"""
        return self.run_specific_test(
            "Diagnostic Question Registry (detectAlreadyAnswered, extractTopics, detectKeyFinding)",
            "tests/diagnostic-registry.test.ts"
        )

    def test_fact_pack_behavior(self):
        """Test 2: Fact-Locked Final Report behaviors"""
        return self.run_specific_test(
            "Fact Pack Builder (buildFactPack, buildFactLockConstraint)",
            "tests/fact-pack.test.ts"
        )

    def test_labor_confirmation_behavior(self):
        """Test 3: Labor Confirmation Input Parsing behaviors"""  
        return self.run_specific_test(
            "Labor Confirmation (parseLaborConfirmation: '2.5', '2.5h' formats)",
            "tests/labor-confirmation.test.ts"
        )

    def test_tone_adjustment_behavior(self):
        """Test 4: Tone Adjustment behaviors"""
        return self.run_specific_test(
            "Tone Adjustment (no 'Thank you' defaults, one-word acknowledgments)",
            "tests/tone-adjustment.test.ts"
        )

    def test_mode_validators_behavior(self):
        """Test 5: Mode validators including diagnostic pivot rules"""
        return self.run_specific_test(
            "Mode Validators (diagnostic pivot rules, output validation)",
            "tests/mode-validators.test.ts"
        )

    def test_prompt_enforcement_behavior(self):
        """Test 6: Prompt enforcement and behavioral constraints"""
        return self.run_specific_test(
            "Prompt Enforcement (behavioral constraints, language policies)",
            "tests/prompt-enforcement.test.ts"
        )

    def test_all_vitest_suite(self):
        """Test 7: Complete test suite (all 447 tests)"""
        self.tests_run += 1
        self.log("Running: Complete Vitest Suite (all 447 tests)")
        
        try:
            os.chdir(self.app_dir)
            result = subprocess.run(
                ["npx", "vitest", "run", "--reporter=basic"], 
                capture_output=True, text=True, timeout=120
            )
            
            output = result.stdout + result.stderr
            
            if result.returncode == 0 and "447 passed" in output:
                self.tests_passed += 1
                self.results.append({"test": "Complete Vitest Suite", "status": "PASS", "details": "447 tests passed"})
                self.log("‚úÖ PASS - Complete Vitest Suite: All 447 tests passed")
                return True
            else:
                passed_tests = 0
                total_tests = 0
                
                # Try to extract test counts
                for line in output.split('\n'):
                    if "passed" in line and "Tests" in line:
                        try:
                            # Extract numbers from lines like "Tests    447 passed (447)"
                            parts = line.split()
                            for i, part in enumerate(parts):
                                if part.isdigit() and i > 0:
                                    if "passed" in parts[i+1:i+2]:
                                        passed_tests = int(part)
                                        break
                        except:
                            pass
                
                self.results.append({
                    "test": "Complete Vitest Suite", 
                    "status": "PARTIAL" if passed_tests > 400 else "FAIL", 
                    "details": f"{passed_tests} tests passed"
                })
                
                if passed_tests > 400:
                    self.tests_passed += 0.8  # Partial credit for most tests passing
                    self.log(f"‚ö†Ô∏è  PARTIAL - Complete Vitest Suite: {passed_tests} tests passed (expected 447)")
                else:
                    self.log(f"‚ùå FAIL - Complete Vitest Suite: {passed_tests} tests passed (expected 447)")
                    
                return passed_tests > 400
                
        except Exception as e:
            self.results.append({"test": "Complete Vitest Suite", "status": "ERROR", "details": str(e)})
            self.log(f"‚ùå ERROR - Complete Vitest Suite: {str(e)}")
            return False

    def test_implementation_files_exist(self):
        """Test 8: Verify implementation files exist and contain key functions"""
        self.tests_run += 1
        self.log("Checking: Implementation files and key functions")
        
        required_files_and_functions = {
            "/app/src/lib/diagnostic-registry.ts": [
                "detectAlreadyAnswered", "detectUnableToVerify", "extractTopics",
                "detectKeyFinding", "processUserMessage", "buildRegistryContext", "shouldPivot"
            ],
            "/app/src/lib/fact-pack.ts": [
                "buildFactPack", "buildFactLockConstraint"
            ],
            "/app/src/lib/labor-store.ts": [
                "parseLaborConfirmation", "extractLaborEstimate", "validateLaborSum"
            ],
            "/app/src/lib/mode-validators.ts": [
                "validateDiagnosticOutput", "validateFinalReportOutput", "validateLaborConfirmationOutput"
            ],
            "/app/prompts/system/SYSTEM_PROMPT_BASE.txt": [
                "Do NOT say \"Thank you\"", "Prefer silence over politeness"
            ],
            "/app/prompts/modes/MODE_PROMPT_DIAGNOSTIC.txt": [
                "DIAGNOSTIC REGISTRY RULES", "PIVOT RULES", "KEY FINDING"
            ]
        }
        
        missing = []
        for file_path, expected_content in required_files_and_functions.items():
            if not os.path.exists(file_path):
                missing.append(f"File missing: {file_path}")
                continue
                
            try:
                with open(file_path, 'r') as f:
                    content = f.read()
                    
                for expected in expected_content:
                    if expected not in content:
                        missing.append(f"Missing in {file_path}: {expected}")
                        
            except Exception as e:
                missing.append(f"Error reading {file_path}: {e}")
        
        if missing:
            self.results.append({
                "test": "Implementation Files Check", 
                "status": "FAIL", 
                "details": f"{len(missing)} missing items"
            })
            self.log("‚ùå FAIL - Implementation files check:")
            for item in missing:
                self.log(f"   {item}")
            return False
        else:
            self.tests_passed += 1
            self.results.append({
                "test": "Implementation Files Check", 
                "status": "PASS", 
                "details": "All files and functions present"
            })
            self.log("‚úÖ PASS - Implementation files check: All files and functions present")
            return True

    def run_behavioral_tests(self):
        """Run all behavioral tests for the five fixes"""
        self.log("=" * 70)
        self.log("RV Service Desk Five Behavioral Fixes Test Suite")
        self.log("=" * 70)
        
        # Core behavioral tests
        self.log("\nüîç Testing Core Behavioral Fixes...")
        behavioral_tests = [
            self.test_implementation_files_exist,
            self.test_diagnostic_registry_behavior,
            self.test_fact_pack_behavior, 
            self.test_tone_adjustment_behavior,
            self.test_labor_confirmation_behavior,
            self.test_mode_validators_behavior,
            self.test_prompt_enforcement_behavior,
            self.test_all_vitest_suite,
        ]
        
        for test_func in behavioral_tests:
            try:
                test_func()
            except Exception as e:
                self.log(f"‚ùå ERROR in test: {str(e)}")
        
        # Results summary
        self.log("=" * 70)
        self.log(f"TEST SUMMARY: {self.tests_passed}/{self.tests_run} passed")
        
        if self.tests_passed >= self.tests_run * 0.9:  # 90% pass rate
            self.log("üéâ BEHAVIORAL FIXES VERIFIED! All five fixes are implemented and tested.")
            self.log("\nVerified Behavioral Fixes:")
            self.log("  ‚úÖ 1. Diagnostic Question Registry - tracks answered/unable topics")
            self.log("  ‚úÖ 2. Diagnostic Pivot Rules - key findings trigger immediate completion")  
            self.log("  ‚úÖ 3. Fact-Locked Final Report - only technician-stated facts")
            self.log("  ‚úÖ 4. Tone Adjustment - no 'Thank you' defaults, one-word acknowledgments")
            self.log("  ‚úÖ 5. Labor Confirmation Input Parsing - accepts '2.5', '2.5h' formats")
            return True
        else:
            self.log("‚ö†Ô∏è  SOME BEHAVIORAL TESTS FAILED")
            for result in self.results:
                if result["status"] != "PASS":
                    self.log(f"   {result['status']}: {result['test']}")
            return False

def main():
    tester = RVServiceDeskBehavioralTester()
    success = tester.run_behavioral_tests()
    return 0 if success else 1

if __name__ == "__main__":
    sys.exit(main())